{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIDJbhoTn6s75vG/oJaf3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alokamgnaneswarasai/MNIST_using-LeNet-architecture/blob/main/assign_2_sys_for_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tWIHN1Yp9nGh"
      },
      "outputs": [],
      "source": [
        "# @title Implementing LeNet architecture and Training on MNIST data set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "gT6hX8t5-ppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor(), transforms.Resize((32,32)),transforms.Normalize((1/255,) ,(1/255,))])   # This will help in transforming the images to tensors\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True,transform=transform)\n"
      ],
      "metadata": {
        "id": "kD1OXcvf_CDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=1000"
      ],
      "metadata": {
        "id": "919Si8wzDb5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader= torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "c6HlJYQn_XPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(1,6,5,1)\n",
        "    self.pool1=nn.MaxPool2d(2,2)\n",
        "    self.conv2=nn.Conv2d(6,16,5,1)\n",
        "    self.pool2=nn.AvgPool2d(2,2)\n",
        "    self.fc1=nn.Linear(16*5*5,120)\n",
        "    self.fc2=nn.Linear(120,84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.pool1(F.tanh(self.conv1(x)))\n",
        "\n",
        "    x=self.pool2(F.tanh(self.conv2(x)))\n",
        "    x=torch.flatten(x,1)\n",
        "    x=F.tanh(self.fc1(x))\n",
        "    x=F.tanh(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "\n",
        "model =LeNet()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E284T20fHjVj",
        "outputId": "3a32130b-9005-4ef5-9b92-c93a52a10d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters())\n",
        "epochs=10"
      ],
      "metadata": {
        "id": "9WK_MB4LAsOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  running_loss =0.0\n",
        "\n",
        "  for data in train_loader:\n",
        "    inputs,target=data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs=model(inputs)\n",
        "\n",
        "    loss=criterion(outputs,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss+=loss.item()\n",
        "\n",
        "  print(f\"Loss in epoch {epoch} is {running_loss}\")\n",
        "\n",
        "print(\"Training finished\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqdZMJPoGfVH",
        "outputId": "51f5036d-7058-4e52-a6af-9a0cc5fcdeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in epoch 0 is 3.2743692100048065\n",
            "Loss in epoch 1 is 2.5251741521060467\n",
            "Loss in epoch 2 is 2.189788019284606\n",
            "Loss in epoch 3 is 1.9494014047086239\n",
            "Loss in epoch 4 is 1.6540712537243962\n",
            "Loss in epoch 5 is 1.4497256493195891\n",
            "Loss in epoch 6 is 1.2898796368390322\n",
            "Loss in epoch 7 is 1.129484687000513\n",
            "Loss in epoch 8 is 0.9497824544087052\n",
            "Loss in epoch 9 is 0.8774829991161823\n",
            "Training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "of2L3MENCqnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=0\n",
        "for data in train_loader:\n",
        "  img=data[0][0]\n",
        "  val=data[1][0]\n",
        "  print(img)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EIHTwvWZaGn",
        "outputId": "971473d4-3e41-4c9b-d791-095be07187ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=img.reshape(1,1,32,32)"
      ],
      "metadata": {
        "id": "9bKA9GGtelum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDgVjOZgfCJR",
        "outputId": "112d34ef-638b-4b23-9754-095f48490307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC9b71kyfU_b",
        "outputId": "7fcc5077-0815-4011-c5e2-40a8082ba1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0446, -5.7268, -2.1943,  3.5268, -0.3174, -1.5266, -5.3843, -0.7174,\n",
              "          0.0372, 13.2162]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt1-bUhZfaXY",
        "outputId": "ffda002d-2546-4598-ab4f-5aa40f31c47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dxy2KcKlfjhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}